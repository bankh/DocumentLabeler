{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.amd.com/bundle/ROCm-Deep-Learning-Guide-v5.3/page/Frameworks_Installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data_drive/CSU_PhD/research/software/dataset/SROIE_PICK\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/data_drive/CSU_PhD/research/software/dataset/SROIE_PICK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating folders for preprocessed dataset\n",
    "!rm -rf boxes_and_transcripts images entities \n",
    "!mkdir boxes_and_transcripts images entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo apt install python3.8-dev\n",
    "#!/usr/bin/python3.8 -m pip install packaging\n",
    "#!/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall\n",
    "!/usr/bin/python3.8 -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script for preprocessing dataset\n",
    "import os\n",
    "import pandas\n",
    "import json\n",
    "import csv\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input dataset\n",
    "data_path = \"/mnt/data_drive/CSU_PhD/research/software/dataset/ICDAR-2019-SROIE/data/\"\n",
    "box_path = data_path + \"box/\"\n",
    "img_path = data_path + \"img/\"\n",
    "key_path = data_path + \"key/\"\n",
    "\n",
    "## Output dataset\n",
    "out_boxes_and_transcripts = \"./boxes_and_transcripts/\"\n",
    "out_images = \"./images/\"\n",
    "out_entities  = \"./entities/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_samples_list =  []\n",
    "for file in os.listdir(data_path + \"box/\"):\n",
    "  \n",
    "  ## Reading csv\n",
    "  with open(box_path +file, \"r\") as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\")\n",
    "    ## arranging dataframe index ,coordinates x1_1,y1_1,x2_1,y2_1,x3_1,y3_1,x4_1,y4_1, transcript\n",
    "    rows = [[1] + x[:8] + [','.join(x[8:]).strip(',')] for x in reader] \n",
    "    df = pandas.DataFrame(rows)\n",
    "  \n",
    "  ## including ner label dataframe index ,coordinates x1_1,y1_1,x2_1,y2_1,x3_1,y3_1,x4_1,y4_1, transcript , ner tag\n",
    "  df[10] = 'other'  \n",
    "  \n",
    "  ##saving file into new dataset folder\n",
    "  jpg = file.replace(\".csv\",\".jpg\")\n",
    "  entities = json.load(open(key_path+file.replace(\".csv\",\".json\")))\n",
    "  for key,value in sorted(entities.items()):\n",
    "    idx = df[df[9].str.contains('|'.join(map(str.strip, value.split(','))))].index\n",
    "    df.loc[idx, 10] = key\n",
    "\n",
    "  shutil.copy(img_path +jpg, out_images)\n",
    "  with open(out_entities + file.replace(\".csv\",\".txt\"),\"w\") as j:  \n",
    "    print(json.dumps(entities), file=j)\n",
    "  \n",
    "  df.to_csv(out_boxes_and_transcripts+file.replace(\".csv\",\".tsv\"),index=False,header=False, quotechar='',escapechar='\\\\',quoting=csv.QUOTE_NONE, )\n",
    "  train_samples_list.append(['receipt',file.replace('.csv','')])\n",
    "train_samples_list = pandas.DataFrame(train_samples_list)\n",
    "train_samples_list.to_csv(\"train_samples_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## document_type, file_name\n",
    "train_samples_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/data_examples_root\n"
     ]
    }
   ],
   "source": [
    "#%cd /mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/data_examples_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_test = pandas.read_csv(\"train_samples_list.csv\",dtype=str)\n",
    "train, test= train_test_split(train_test,test_size=0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy train data into PICK-pytorch data folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "  shutil.copy(out_boxes_and_transcripts+str(row[2])+\".tsv\",\n",
    "              '/mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/data_examples_root/boxes_and_transcripts/')\n",
    "  shutil.copy(out_images+str(row[2])+\".jpg\",\n",
    "              '/mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/data_examples_root/images/')\n",
    "  shutil.copy(out_entities +str(row[2])+\".txt\", \n",
    "              '/mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/data_examples_root/entities/')\n",
    "\n",
    "train.drop(['Unnamed: 0'], \n",
    "           axis = 1,\n",
    "           inplace = True)\n",
    "train.reset_index(inplace= True)\n",
    "train.drop(['index'], \n",
    "           axis = 1,\n",
    "           inplace = True)\n",
    "train.to_csv(\"/mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/data_examples_root/train_samples_list.csv\",\n",
    "             header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy test data into PICK-pytorch data folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/test_data_example/entities/\n",
    "!rm -rf /mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/test_data_example/images/\n",
    "!rm -rf /mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/test_data_example/boxes_and_transcripts/\n",
    "!mkdir -p /mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/test_data_example/entities/\n",
    "!mkdir -p /mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/test_data_example/images/\n",
    "!mkdir -p /mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/test_data_example/boxes_and_transcripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in test.iterrows():\n",
    "  shutil.copy(out_boxes_and_transcripts+str(row[2])+\".tsv\",'/mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/test_data_example/boxes_and_transcripts/')\n",
    "  shutil.copy(out_images+str(row[2])+\".jpg\",'/mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/test_data_example/images/')\n",
    "  shutil.copy(out_entities +str(row[2])+\".txt\", '/mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/test_data_example/entities/')\n",
    "\n",
    "test.drop(['Unnamed: 0'], axis = 1,inplace = True)\n",
    "test.reset_index(inplace= True)\n",
    "test.drop(['index'], axis = 1,inplace = True)\n",
    "test.to_csv(\"/mnt/data_drive/CSU_PhD/research/software/PICK-pytorch/data/test_data_example/test_samples_list.csv\",header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing data once it is copied into PICK-pytorch data folder\n",
    "!rm -rf ./boxes_and_transcripts\n",
    "!rm -rf ./images\n",
    "!rm -rf ./entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data_drive/CSU_PhD/research/software/PICK-pytorch\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/data_drive/CSU_PhD/research/software/PICK-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils/entities_list.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils/entities_list.py\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Author: Wenwen Yu\n",
    "# @Created Time: 7/8/2020 9:34 PM\n",
    "\n",
    "Entities_list = [\n",
    "    \"company\",\n",
    "    \"address\",\n",
    "    \"date\",\n",
    "    \"total\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/rocm/lib:/usr/lib/x86_64-linux-gnu\n",
    "# sudo ldconfig\n",
    "# ImportError: libMIOpen.so.1: cannot open shared object file: No such file or directory\n",
    "# !sudo apt install miopen-hip miopen-hip-dev\n",
    "\n",
    "# !sudo ln -s /opt/rocm-5.3.0/lib/libroctx64.so.4.1.0 /opt/rocm-5.3.0/lib/libroctx64.so.1\n",
    "# !sudo ln -s /opt/rocm-5.3.0/lib/libroctracer64.so.4.1.0 /opt/rocm-5.3.0/lib/libroctracer64.so.1\n",
    "\n",
    "\n",
    "# ImportError: librccl.so.1: cannot open shared object file: No such file or directory\n",
    "# !wget http://mirrors.edge.kernel.org/ubuntu/pool/main/g/gcc-10/gcc-10-base_10-20200411-0ubuntu1_amd64.deb\n",
    "# !wget http://mirrors.xmission.com/ubuntu/pool/main/g/gcc-10/libgcc-s1_10-20200411-0ubuntu1_amd64.deb\n",
    "\n",
    "# !sudo dpkg -i ~/Downloads/gcc-10-base_10-20200411-0ubuntu1_amd64.deb\n",
    "# !sudo dpkg -i ~/Downloads/libgcc-s1_10-20200411-0ubuntu1_amd64.deb\n",
    "# !sudo apt install rccl\n",
    "\n",
    "# ImportError: libtinfo.so.6: cannot open shared object file: No such file or directory\n",
    "# !sudo apt install libtinfo-dev #Check with apt-cache policy libtinfo-dev first to make sure\n",
    "# !sudo ln -s /usr/lib/x86_64-linux-gnu/libtinfo.so /usr/lib/x86_64-linux-gnu/libtinfo.so.5\n",
    "\n",
    "# ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.26' not found\n",
    "# !strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep -i glib\n",
    "# !sudo add-apt-repository ppa:ubuntu-toolchain-r/test\n",
    "# !sudo apt update\n",
    "# !sudo apt upgrade libstdc++6\n",
    "\n",
    "#ImportError: /lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found \n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the docker server, since the initialization of the VS code is via the add-on it doesn't restart the VS Code.\n",
    "Current environment is the virtual one,\n",
    "\n",
    "```\n",
    "$ sudo apt install jupyter # Install jupyter\n",
    "$ jupyter notebook --allow-root # Allow to start jupyter server as root\n",
    "```\n",
    "\n",
    "Then click on the kernel selection for the ipython notebook. It will allow you to select the new notebook server.\n",
    "Select that server and start the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.2.1\n",
      "  Downloading scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tabulate==0.8.7\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Collecting overrides==3.0.0\n",
      "  Downloading overrides-3.0.0.tar.gz (4.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting opencv_python==4.3.0.36\n",
      "  Downloading opencv_python-4.3.0.36-cp38-cp38-manylinux2014_x86_64.whl (43.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy==1.22.0\n",
      "  Downloading numpy-1.22.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hCollecting pandas==1.0.5\n",
      "  Downloading pandas-1.0.5-cp38-cp38-manylinux1_x86_64.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: allennlp==1.0.0 in /root/venv/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (1.0.0)\n",
      "Collecting tqdm==4.47.0\n",
      "  Downloading tqdm-4.47.0-py2.py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: overrides\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for overrides: filename=overrides-3.0.0-py3-none-any.whl size=5668 sha256=babf6ebfab3850bcfa200a293fefb3315789c541267531c4956be2a6ba8e356a\n",
      "  Stored in directory: /root/.cache/pip/wheels/4a/62/c2/1a021999d160fce8988607bcd416f1da7a494b476ef3ce59a7\n",
      "Successfully built overrides\n",
      "Installing collected packages: tabulate, overrides, opencv_python, tqdm, scikit-learn, pandas, numpy\n",
      "  Attempting uninstall: opencv_python\n",
      "    Found existing installation: opencv-python 4.7.0.68\n",
      "    Uninstalling opencv-python-4.7.0.68:\n",
      "      Successfully uninstalled opencv-python-4.7.0.68\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Uninstalling tqdm-4.64.1:\n",
      "      Successfully uninstalled tqdm-4.64.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "Successfully installed numpy-1.22.0 opencv_python-4.3.0.36 overrides-3.0.0 pandas-1.0.5 scikit-learn-1.2.1 tabulate-0.8.7 tqdm-4.47.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -r requirements.txt --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /root/venv/lib/python3.8/site-packages (4.3.0.36)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /root/venv/lib/python3.8/site-packages (from opencv-python) (1.22.0)\n",
      "Hit:1 http://repo.radeon.com/rocm/apt/3.5.1 xenial InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease                       \u001b[0m\n",
      "Hit:3 http://security.ubuntu.com/ubuntu focal-security InRelease             \u001b[33m\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "2 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsm6 is already the newest version (2:1.2.3-1).\n",
      "libxext6 is already the newest version (2:1.3.4-0ubuntu1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libxrender-dev is already the newest version (1:0.9.10-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "#ImportError: libSM.so.6: cannot open shared object file: No such file or directory\n",
    "!pip install opencv-python\n",
    "!apt update && apt install -y libsm6 libxext6\n",
    "!apt-get install -y libxrender-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.6 in /root/venv/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: spacy in /root/venv/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: thinc in /root/venv/lib/python3.8/site-packages (8.1.7)\n",
      "Requirement already satisfied: catalogue in /root/venv/lib/python3.8/site-packages (2.0.8)\n",
      "Requirement already satisfied: confection in /root/venv/lib/python3.8/site-packages (0.0.4)\n",
      "Requirement already satisfied: pydantic in /root/venv/lib/python3.8/site-packages (1.10.4)\n",
      "Requirement already satisfied: srsly in /root/venv/lib/python3.8/site-packages (2.4.5)\n",
      "Requirement already satisfied: wasabi in /root/venv/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: blis in /root/venv/lib/python3.8/site-packages (0.9.1)\n",
      "Requirement already satisfied: cymem in /root/venv/lib/python3.8/site-packages (2.0.7)\n",
      "Requirement already satisfied: preshed in /root/venv/lib/python3.8/site-packages (3.0.8)\n",
      "Requirement already satisfied: murmurhash in /root/venv/lib/python3.8/site-packages (1.0.9)\n",
      "Requirement already satisfied: langcodes in /root/venv/lib/python3.8/site-packages (3.3.0)\n",
      "Requirement already satisfied: typer in /root/venv/lib/python3.8/site-packages (0.7.0)\n",
      "Requirement already satisfied: click in /root/venv/lib/python3.8/site-packages (8.1.3)\n",
      "Requirement already satisfied: boto3 in /root/venv/lib/python3.8/site-packages (1.26.66)\n",
      "Requirement already satisfied: botocore in /root/venv/lib/python3.8/site-packages (1.29.66)\n",
      "Requirement already satisfied: jmespath in /root/venv/lib/python3.8/site-packages (1.0.1)\n",
      "Requirement already satisfied: pytz in /root/venv/lib/python3.8/site-packages (2022.7.1)\n",
      "Requirement already satisfied: allennlp==1.0.0 in /root/venv/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: transformers==3.3.0 in /root/venv/lib/python3.8/site-packages (3.3.0)\n",
      "Requirement already satisfied: sentencepiece in /root/venv/lib/python3.8/site-packages (0.1.97)\n",
      "Requirement already satisfied: sacremoses in /root/venv/lib/python3.8/site-packages (0.0.53)\n",
      "Requirement already satisfied: joblib in /root/venv/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: jsonpickle in /root/venv/lib/python3.8/site-packages (3.0.1)\n",
      "Requirement already satisfied: h5py in /root/venv/lib/python3.8/site-packages (3.8.0)\n",
      "Requirement already satisfied: nltk in /root/venv/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: scipy in /root/venv/lib/python3.8/site-packages (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl in /root/venv/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: protobuf==3.20.0 in /root/venv/lib/python3.8/site-packages (3.20.0)\n",
      "Requirement already satisfied: tensorboardX in /root/venv/lib/python3.8/site-packages (2.5.1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__\n",
    "\n",
    "!python -m pip install torchtext==0.6 spacy thinc catalogue confection pydantic srsly wasabi blis cymem preshed murmurhash langcodes typer click boto3 botocore jmespath pytz  --no-deps\n",
    "!python -m pip install allennlp==1.0.0 transformers==3.3.0 sentencepiece sacremoses joblib jsonpickle h5py nltk scipy threadpoolctl protobuf==3.20.0 tensorboardX --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "!python -m torch.distributed.launch --nnode=1 --node_rank=0 --nproc_per_node=1 \\\n",
    "           train.py -c config.json -d 0 --local_world_size 1\n",
    "#!python3 train_.py #--resume /content/drive/MyDrive/Colab_Notebooks/NLP/KG_KE/PICK-pytorch/saved/models/PICK_Default/test_0118_234222/model_best.pth ##uncomment for resume training\n",
    "#!python train_.py #--resume /content/drive/MyDrive/Colab_Notebooks/NLP/KG_KE/PICK-pytorch/saved/models/PICK_Default/test_0118_234222/model_best.pth ##uncomment for resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[W Module.cpp:473] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())\n",
      "[W Module.cpp:473] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())\n",
      "[W Module.cpp:473] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())\n",
      "[W Module.cpp:473] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())\n",
      "[W Module.cpp:473] Warning: Disabling benchmark mode for MIOpen is NOT supported. Overriding value to True (function operator())\n",
      "[2023-02-07 21:56:31,676 - train - INFO] - Distributed GPU training model start...\n",
      "[2023-02-07 21:56:31,676 - train - INFO] - [Process 6220] Initializing process group with: {'MASTER_ADDR': '127.0.0.1', 'MASTER_PORT': '5555', 'RANK': '0', 'WORLD_SIZE': '5'}\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bash dist_train.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
